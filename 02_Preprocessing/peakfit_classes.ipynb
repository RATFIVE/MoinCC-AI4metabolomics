{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: data, expected peaks (substrate and metabolite)(dictionary?/two lists?\n",
    "data = pd.read_csv('../Data/FA_20231113_2H_yeast_Pyruvate-d3_5.csv')\n",
    "\n",
    "#expected peaks for different substrates\n",
    "Pyruvate_compound = ['Substrate', 'metabolite1', 'metabolite2']\n",
    "peaks_pyruvate= [2.468, 1.2261, 1.9775]\n",
    "\n",
    "spectra_data= data.iloc[:,1:]\n",
    "chem_shifts = data.iloc[:,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# functions so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def peak_fit(intensity, chem_shifts, threshold_percentile):\n",
    "    \"\"\"calculates possible peaks as minima of the second derivative and returns list of peaks\n",
    "\n",
    "    Args:\n",
    "        spectra_data (_type_): x data of spectra\n",
    "        chem_shifts (_type_): y data of spectra\n",
    "        threshold_percentile (int | float): Threshold above which the relevant data lies\n",
    "\n",
    "    Returns:\n",
    "        list: peak positions\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(intensity, threshold_percentile)\n",
    "    first_derivative = np.gradient(intensity, chem_shifts)\n",
    "    second_derivative = np.gradient(first_derivative, chem_shifts)\n",
    "    third_derivative = np.gradient(second_derivative, chem_shifts)\n",
    "    fourth_derivative = np.gradient(third_derivative, chem_shifts)\n",
    "\n",
    "    sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "    peak_mask = (intensity > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "    peak_mask[1:] &= sign_change\n",
    "\n",
    "    return chem_shifts[peak_mask].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakfit_sum(spectra_data, chem_shifts, threshold):\n",
    "    \"\"\"sums up all spectra and returns list of found peaks\n",
    "\n",
    "    Args:\n",
    "        filename (str): file with spectra data\n",
    "        threshold_percentile (int | float): Threshold above which the relevant data lies\n",
    "    \"\"\"\n",
    "    sum_of_spectra = np.sum(spectra_data, axis=1)\n",
    "    # peak_pos = peak_fit(sum_of_spectra, chem_shifts, threshold)\n",
    "\n",
    "    threshold = np.percentile(sum_of_spectra, threshold)\n",
    "\n",
    "    first_derivative = np.gradient(sum_of_spectra, chem_shifts)\n",
    "    second_derivative = np.gradient(first_derivative, chem_shifts)\n",
    "    third_derivative = np.gradient(second_derivative, chem_shifts)\n",
    "    fourth_derivative = np.gradient(third_derivative, chem_shifts)\n",
    "\n",
    "    sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "    peak_mask = (sum_of_spectra > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "    peak_mask[1:] &= sign_change\n",
    "\n",
    "    peak_pos= chem_shifts[peak_mask].tolist()\n",
    "\n",
    "    return peak_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_water_singlet(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Diese Funktion wird so angepasst, dass sie jedes Spektrum anhand eines bestimmten Peaks 'normalisiert'.\n",
    "    Jedes Spektrum wird einzeln behandelt.\n",
    "    \"\"\"\n",
    "    # Kopieren des DataFrames, um die ursprünglichen Daten nicht zu verändern\n",
    "    data_normalized = pd.DataFrame()\n",
    "    data_normalized['chem_shift'] = data.iloc[:,0]  # Chemische Verschiebungen beibehalten\n",
    "    \n",
    "    # Über jede Spektrumsspalte iterieren (jedes Spektrum)\n",
    "    for col in data.columns[1:]:\n",
    "        intensity = data[col]\n",
    "        chem_shifts = data.iloc[:, 0]\n",
    "        \n",
    "        # Nutzung der peak_fit Funktion, um Peaks für jedes Spektrum zu ermitteln\n",
    "        peak_pos = peak_fit(intensity.values, chem_shifts.values, 85)  # Annahme: threshold_percentile=85\n",
    "        \n",
    "        # Bestimmung des dem Wasserpeak am nächsten liegenden Peaks\n",
    "        water = 4.7\n",
    "        \n",
    "        if peak_pos:\n",
    "            closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "            \n",
    "            # Adjustierung der chemischen Verschiebung basierend auf dem nächsten Peak\n",
    "            adjusted_shifts = chem_shifts + (water - closest_peak)\n",
    "            data_normalized[col] = intensity.set_axis(adjusted_shifts.index)\n",
    "        else:\n",
    "            # Falls keine Peaks gefunden wurden, Kopie der Originalintensitäten\n",
    "            data_normalized[col] = intensity\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_water_singlet(data: pd.DataFrame, threshold=85, delta_threshold=2, min_threshold=50):\n",
    "    \"\"\"\n",
    "    Normalisiert jedes Spektrum im DataFrame basierend auf dem nächsten Wasserpeak, wobei der Threshold angepasst wird.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Spectra-Daten.\n",
    "        threshold (int, optional): Anfangsschwelle für die Peak-Suche. Standardmäßig 85.\n",
    "        delta_threshold (int, optional): Reduktionsbetrag für den Threshold. Standardmäßig 2.\n",
    "        min_threshold (int, optional): Minimale Schwelle für die Peak-Suche. Standardmäßig 50.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit normalisierten Daten.\n",
    "    \"\"\"\n",
    "    data_normalized = pd.DataFrame()\n",
    "    data_normalized['chem_shift'] = data.iloc[:,0]  \n",
    "    \n",
    "    # Iteration durch jede Spalte (jedes Spektrum).\n",
    "    for col in data.columns[1:]:\n",
    "        intensity = data[col]\n",
    "        chem_shifts = data.iloc[:, 0]\n",
    "        \n",
    "        current_threshold = threshold\n",
    "        peak_found = False\n",
    "        while not peak_found and current_threshold >= min_threshold:\n",
    "            # Nutzung der peak_fit Funktion mit dem aktuellen Threshold\n",
    "            peak_pos = peak_fit(intensity.values, chem_shifts.values, current_threshold)\n",
    "            \n",
    "            # Suche nach Peaks im Wasserbereich\n",
    "            water_peaks = [peak for peak in peak_pos if 4.6 <= peak <= 4.8]\n",
    "            \n",
    "            if water_peaks:\n",
    "                closest_peak = min(water_peaks, key=lambda x: abs(x - 4.7))\n",
    "                peak_found = True\n",
    "            else:\n",
    "                current_threshold -= delta_threshold\n",
    "        \n",
    "        # Wenn ein passender Peak gefunden wurde, chemische Schichten adjustieren\n",
    "        if peak_found:\n",
    "            adjusted_shifts = chem_shifts + (4.7 - closest_peak)\n",
    "            data_normalized[col] = intensity.set_axis(adjusted_shifts.index)\n",
    "        else:\n",
    "            # Sicherheitsfallback, falls kein Peak gefunden wurde\n",
    "            print(f\"Kein Peak für {col} im Bereich von 4.6 bis 4.8 gefunden, auch nicht mit min_threshold={min_threshold}.\")\n",
    "            data_normalized[col] = intensity  # Originalintensitäten übernehmen\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_water(data:pd.DataFrame):\n",
    "    \"\"\"adjusts the data to the chem_shift(water) = 4.7, based on the closest peak in summed up spectra\n",
    "    --> needs existing function 'peakfit_sum', peak_fit\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): spectra data with chem_shift in first column\n",
    "\n",
    "    Returns:\n",
    "        data_normalized (pd.DataFrame): dataframe with normalized data\n",
    "    \"\"\"\n",
    "\n",
    "    spectra_data= data.iloc[:,1:]\n",
    "    chem_shifts = data.iloc[:,0] \n",
    "\n",
    "    peak_pos = peakfit_sum(spectra_data, chem_shifts, 85)\n",
    "\n",
    "    #identify water peak (closest to 4.7\n",
    "    water = 4.7\n",
    "    closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "\n",
    "    # reposition the whole spectra\n",
    "    data_normalized = pd.DataFrame(chem_shifts.copy() + ( 4.7 - closest_peak))\n",
    "    data_normalized = pd.concat([data_normalized, data.iloc[:, 1:]], axis=1)\n",
    "\n",
    "    # Neubenennung der Spalten, um die Originalstruktur zu erhalten\n",
    "    data_normalized.columns = data.columns\n",
    "\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_identify(data_normalized: pd.DataFrame, expected_peaks: list,  compound_names: list, initial_threshold = 85, max_shift = 0.15):\n",
    "    \"\"\"searches for peaks and matches them to the closest expected peak respecting the maximal shift. \n",
    "    Unidentified peaks are added to other(list). \n",
    "    Threshold is lowered until all expected peaks are found or number of other peaks succeeds numer of expected peaks\n",
    "    \n",
    "    needs existing function 'peakfit_sum'\n",
    "    \n",
    "    Args:\n",
    "        data_normalized (pd.DataFrame): _description_\n",
    "        compound_names (list): list with names of expected compunds (optional)\n",
    "        expected_peaks (list): list with positions of expected peaks\n",
    "        max_shift: maximum distance to expected peak position for \n",
    "\n",
    "    Returns:\n",
    "        found (list): list with identified peaks most likely the expected ones\n",
    "        other (list):  list with other found peaks\n",
    "    \"\"\"\n",
    "\n",
    "    spectra_data= data_normalized.iloc[:,1:]\n",
    "    chem_shifts = data_normalized.iloc[:,0]\n",
    "\n",
    "    #create enpty lists for found and identified peaks\n",
    "    found = [None] * len(expected_peaks)\n",
    "    other = []\n",
    "    threshold = initial_threshold\n",
    "\n",
    "    while None in found or len(other) <= len(found):\n",
    "        \n",
    "        #search for peaks above given threshold\n",
    "        detected_peaks = peakfit_sum(spectra_data, chem_shifts, threshold)\n",
    "        \n",
    "        for peak in detected_peaks:\n",
    "            distances = [abs(peak - expected_peak) for expected_peak in expected_peaks]\n",
    "            min_distance = min(distances)\n",
    "            index = distances.index(min_distance)\n",
    "            \n",
    "            if min_distance <= max_shift:\n",
    "                if found[index] is None:\n",
    "                    found[index] = peak\n",
    "                elif found[index] != peak:\n",
    "                    other.append(peak)\n",
    "            elif min_distance > max_shift:\n",
    "                other.append(peak)\n",
    "            \n",
    "        threshold -= 2\n",
    "\n",
    "        if threshold < 0 or None not in found or len(other) > len(found):\n",
    "            if None not in found:\n",
    "                #print('alle peaks gefunden')\n",
    "                break\n",
    "            else: \n",
    "                break\n",
    "\n",
    "    print(\"Found Peaks: \", found)\n",
    "    print(\"Other Peaks: \", other)\n",
    "\n",
    "    return found, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_df(data, expected_peaks, compound_names, shift_tol=0.01, viz=True, min_cols_per_section = 20):\n",
    "\n",
    "    # normalize data\n",
    "    df = normalize_water(data)\n",
    "   \n",
    "    # Split into section with at least 20 columns each\n",
    "    cols_to_divide = len(df.columns)-1 #-1 because first column is chemical shift\n",
    "    num_sections = max(cols_to_divide // min_cols_per_section, 1) if cols_to_divide > min_cols_per_section else 1\n",
    "\n",
    "    cols_per_section = cols_to_divide // num_sections\n",
    "    extra_cols = cols_to_divide % num_sections  # Extra columns to distribute\n",
    "\n",
    "    sections = []\n",
    "    start_col = 1 #ignore first column\n",
    "    col_sect = []\n",
    "\n",
    "    for section in range(num_sections):\n",
    "        extra = 1 if section < extra_cols else 0\n",
    "        end_col = start_col + cols_per_section + extra\n",
    "        #sections.append(df.iloc[:, start_col:end_col])\n",
    "        sections.append(df.iloc[:, [0] + list(range(start_col, end_col))]) #add column with chem_shift to each section\n",
    "        start_col = end_col\n",
    "        col_sect.extend([f\"{section + 1}\"] * (cols_per_section + extra)) #column entries for final dataframe\n",
    "\n",
    "    found_lists = []\n",
    "    other_lists = []\n",
    "\n",
    "    # Find peaks for each section\n",
    "    for df_section in sections:\n",
    "        found, other = peak_identify(df_section, expected_peaks, compound_names)\n",
    "        found_lists.append(found)\n",
    "        other_lists.append(other)\n",
    "\n",
    "    \n",
    "    #create final dataframe\n",
    "    final_df = pd.DataFrame({\n",
    "        'Column': df.columns[1:],  # Exclude the chemical shift from the final DataFrame columns\n",
    "        'section': col_sect\n",
    "    })\n",
    "\n",
    "    \n",
    "    peaks_data = {'Found Peaks': [], 'Other Peaks': []}\n",
    "    for i in range(num_sections):\n",
    "        section_length = len(sections[i].columns) - 1  # -1 to ignore the chemical shift column\n",
    "        peaks_data['Found Peaks'].extend([found_lists[i]] * section_length)\n",
    "        peaks_data['Other Peaks'].extend([other_lists[i]] * section_length)\n",
    "\n",
    "    final_df['Found Peaks'] = peaks_data['Found Peaks']\n",
    "    final_df['Other Peaks'] = peaks_data['Other Peaks']\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9673300000000005]\n",
      "Other Peaks:  [1.5356500000000004, 2.2646300000000004, 4.68778]\n",
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9673300000000005]\n",
      "Other Peaks:  [1.3849600000000004, 1.5356500000000004, 4.68778]\n",
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9714100000000003]\n",
      "Other Peaks:  [1.3890400000000005, 1.5356500000000004, 4.6918500000000005]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9714100000000003]\n",
      "Other Peaks:  [1.0673100000000004, 1.3849600000000004, 1.5356500000000004, 4.70814]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9714100000000003]\n",
      "Other Peaks:  [1.0713800000000004, 1.3808900000000004, 1.5356500000000004, 4.70814]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9754800000000003]\n",
      "Other Peaks:  [1.0713800000000004, 1.3849600000000004, 1.5356500000000004, 4.716290000000001]\n"
     ]
    }
   ],
   "source": [
    "peak_df = peak_df(data, expected_peaks=peaks_pyruvate, compound_names= Pyruvate_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0713800000000004, 1.3849600000000004, 1.5356500000000004, 4.716290000000001]\n"
     ]
    }
   ],
   "source": [
    "print(peak_df['Other Peaks'].loc[127])#[127])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectraAnalysis:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def peakfit_sum(self, spectra_data, chem_shifts, threshold):\n",
    "        \"\"\"Summen der Spektren und Rückgabe einer Liste gefundener Peaks\"\"\"\n",
    "        sum_of_spectra = np.sum(spectra_data, axis=1)\n",
    "        threshold = np.percentile(sum_of_spectra, threshold)\n",
    "\n",
    "        first_derivative = np.gradient(sum_of_spectra, chem_shifts)\n",
    "        second_derivative = np.gradient(first_derivative, chem_shifts)\n",
    "        third_derivative = np.gradient(second_derivative, chem_shifts)\n",
    "        fourth_derivative = np.gradient(third_derivative, chem_shifts)\n",
    "\n",
    "        sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "        peak_mask = (sum_of_spectra > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "        peak_mask[1:] &= sign_change\n",
    "\n",
    "        peak_pos = chem_shifts[peak_mask].tolist()\n",
    "        return peak_pos\n",
    "\n",
    "    def normalize_water(self, data):\n",
    "        \"\"\"Anpassung der Daten basierend auf dem Wasser-Peak\"\"\"\n",
    "        spectra_data = data.iloc[:, 1:]\n",
    "        chem_shifts = data.iloc[:, 0]\n",
    "\n",
    "        peak_pos = self.peakfit_sum(spectra_data, chem_shifts, 85)\n",
    "        water = 4.7\n",
    "        closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "\n",
    "        data_normalized = pd.DataFrame(chem_shifts.copy() + (4.7 - closest_peak))\n",
    "        data_normalized = pd.concat([data_normalized, data.iloc[:, 1:]], axis=1)\n",
    "        data_normalized.columns = data.columns\n",
    "        return data_normalized\n",
    "\n",
    "    def peak_identify(self, data_normalized, expected_peaks, compound_names, initial_threshold=85, max_shift=0.15):\n",
    "        \"\"\"Identifizierung von Peaks und Zuordnung zu erwarteten Peaks\"\"\"\n",
    "        spectra_data = data_normalized.iloc[:, 1:]\n",
    "        chem_shifts = data_normalized.iloc[:, 0]\n",
    "\n",
    "        found = [None] * len(expected_peaks)\n",
    "        other = []\n",
    "        threshold = initial_threshold\n",
    "\n",
    "        while None in found or len(other) <= len(found):\n",
    "            detected_peaks = self.peakfit_sum(spectra_data, chem_shifts, threshold)\n",
    "            for peak in detected_peaks:\n",
    "                distances = [abs(peak - expected_peak) for expected_peak in expected_peaks]\n",
    "                min_distance = min(distances)\n",
    "                index = distances.index(min_distance)\n",
    "\n",
    "                if min_distance <= max_shift:\n",
    "                    if found[index] is None:\n",
    "                        found[index] = peak\n",
    "                    elif found[index] != peak:\n",
    "                        other.append(peak)\n",
    "                else:\n",
    "                    other.append(peak)\n",
    "\n",
    "            threshold -= 2\n",
    "            if threshold < 0 or None not in found or len(other) > len(found):\n",
    "                break\n",
    "\n",
    "        print(\"Found Peaks: \", found)\n",
    "        print(\"Other Peaks: \", other)\n",
    "\n",
    "        return found, other\n",
    "\n",
    "    def peak_df(self, data, expected_peaks, compound_names, min_cols_per_section=20):\n",
    "        \"\"\"creates dataframe with expected peaks and other found peaks\"\"\"\n",
    "        #normalize data\n",
    "        df = self.normalize_water(data)\n",
    "    \n",
    "        # Split into section with at least 20 columns each\n",
    "        cols_to_divide = len(df.columns)-1 #-1 because first column is chemical shift\n",
    "        num_sections = max(cols_to_divide // min_cols_per_section, 1) if cols_to_divide > min_cols_per_section else 1\n",
    "\n",
    "        cols_per_section = cols_to_divide // num_sections\n",
    "        extra_cols = cols_to_divide % num_sections  # Extra columns to distribute\n",
    "\n",
    "        sections = []\n",
    "        start_col = 1 #ignore first column\n",
    "        col_sect = []\n",
    "\n",
    "        for section in range(num_sections):\n",
    "            extra = 1 if section < extra_cols else 0\n",
    "            end_col = start_col + cols_per_section + extra\n",
    "            #sections.append(df.iloc[:, start_col:end_col])\n",
    "            sections.append(df.iloc[:, [0] + list(range(start_col, end_col))]) #add column with chem_shift to each section\n",
    "            start_col = end_col\n",
    "            col_sect.extend([f\"{section + 1}\"] * (cols_per_section + extra)) #column entries for final dataframe\n",
    "\n",
    "        found_lists = []\n",
    "        other_lists = []\n",
    "\n",
    "        # Find peaks for each section\n",
    "        for df_section in sections:\n",
    "            found, other = self.peak_identify(df_section, expected_peaks, compound_names)\n",
    "            found_lists.append(found)\n",
    "            other_lists.append(other)\n",
    "\n",
    "        \n",
    "        #create final dataframe\n",
    "        final_df = pd.DataFrame({\n",
    "            'Column': df.columns[1:],  # Exclude the chemical shift from the final DataFrame columns\n",
    "            'section': col_sect\n",
    "        })\n",
    "\n",
    "        \n",
    "        peaks_data = {'Found Peaks': [], 'Other Peaks': []}\n",
    "        for i in range(num_sections):\n",
    "            section_length = len(sections[i].columns) - 1  # -1 to ignore the chemical shift column\n",
    "            peaks_data['Found Peaks'].extend([found_lists[i]] * section_length)\n",
    "            peaks_data['Other Peaks'].extend([other_lists[i]] * section_length)\n",
    "\n",
    "        final_df['Found Peaks'] = peaks_data['Found Peaks']\n",
    "        final_df['Other Peaks'] = peaks_data['Other Peaks']\n",
    "\n",
    "        return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m peak_positions \u001b[38;5;241m=\u001b[39m \u001b[43manalyser\u001b[49m\u001b[38;5;241m.\u001b[39mpeakfit_sum(spectra_data, chem_shifts, threshold)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analyser' is not defined"
     ]
    }
   ],
   "source": [
    "peak_positions = analyser.peakfit_sum(spectra_data, chem_shifts, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_df(data, expected_peaks=peaks_pyruvate, compound_names= Pyruvate_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9673300000000005]\n",
      "Other Peaks:  [1.5356500000000004, 2.2646300000000004, 4.68778]\n",
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9673300000000005]\n",
      "Other Peaks:  [1.3849600000000004, 1.5356500000000004, 4.68778]\n",
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9714100000000003]\n",
      "Other Peaks:  [1.3890400000000005, 1.5356500000000004, 4.6918500000000005]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9714100000000003]\n",
      "Other Peaks:  [1.0673100000000004, 1.3849600000000004, 1.5356500000000004, 4.70814]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9714100000000003]\n",
      "Other Peaks:  [1.0713800000000004, 1.3808900000000004, 1.5356500000000004, 4.70814]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9754800000000003]\n",
      "Other Peaks:  [1.0713800000000004, 1.3849600000000004, 1.5356500000000004, 4.716290000000001]\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "import sys\n",
    "sys.path.append('../app')\n",
    "\n",
    "from peakpos_df import SpectraAnalysis\n",
    "# Jetzt können Sie SpectraAnalysis nutzen\n",
    "analyser = SpectraAnalysis()\n",
    "peak_positions = analyser.peak_df(data, expected_peaks=peaks_pyruvate, compound_names= Pyruvate_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>section</th>\n",
       "      <th>Found Peaks</th>\n",
       "      <th>Other Peaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#1</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.4275300000000004, 1.2261300000000004, 1.967...</td>\n",
       "      <td>[1.5356500000000004, 2.2646300000000004, 4.68778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#2</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.4275300000000004, 1.2261300000000004, 1.967...</td>\n",
       "      <td>[1.5356500000000004, 2.2646300000000004, 4.68778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#3</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.4275300000000004, 1.2261300000000004, 1.967...</td>\n",
       "      <td>[1.5356500000000004, 2.2646300000000004, 4.68778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#4</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.4275300000000004, 1.2261300000000004, 1.967...</td>\n",
       "      <td>[1.5356500000000004, 2.2646300000000004, 4.68778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#5</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.4275300000000004, 1.2261300000000004, 1.967...</td>\n",
       "      <td>[1.5356500000000004, 2.2646300000000004, 4.68778]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#126</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.4275300000000004, 1.2302100000000005, 1.975...</td>\n",
       "      <td>[1.0713800000000004, 1.3849600000000004, 1.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#127</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.4275300000000004, 1.2302100000000005, 1.975...</td>\n",
       "      <td>[1.0713800000000004, 1.3849600000000004, 1.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#128</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.4275300000000004, 1.2302100000000005, 1.975...</td>\n",
       "      <td>[1.0713800000000004, 1.3849600000000004, 1.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#129</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.4275300000000004, 1.2302100000000005, 1.975...</td>\n",
       "      <td>[1.0713800000000004, 1.3849600000000004, 1.535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>FA_20231113_2H_yeast_1.5.ser#130</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.4275300000000004, 1.2302100000000005, 1.975...</td>\n",
       "      <td>[1.0713800000000004, 1.3849600000000004, 1.535...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Column section  \\\n",
       "0      FA_20231113_2H_yeast_1.5.ser#1       1   \n",
       "1      FA_20231113_2H_yeast_1.5.ser#2       1   \n",
       "2      FA_20231113_2H_yeast_1.5.ser#3       1   \n",
       "3      FA_20231113_2H_yeast_1.5.ser#4       1   \n",
       "4      FA_20231113_2H_yeast_1.5.ser#5       1   \n",
       "..                                ...     ...   \n",
       "125  FA_20231113_2H_yeast_1.5.ser#126       6   \n",
       "126  FA_20231113_2H_yeast_1.5.ser#127       6   \n",
       "127  FA_20231113_2H_yeast_1.5.ser#128       6   \n",
       "128  FA_20231113_2H_yeast_1.5.ser#129       6   \n",
       "129  FA_20231113_2H_yeast_1.5.ser#130       6   \n",
       "\n",
       "                                           Found Peaks  \\\n",
       "0    [2.4275300000000004, 1.2261300000000004, 1.967...   \n",
       "1    [2.4275300000000004, 1.2261300000000004, 1.967...   \n",
       "2    [2.4275300000000004, 1.2261300000000004, 1.967...   \n",
       "3    [2.4275300000000004, 1.2261300000000004, 1.967...   \n",
       "4    [2.4275300000000004, 1.2261300000000004, 1.967...   \n",
       "..                                                 ...   \n",
       "125  [2.4275300000000004, 1.2302100000000005, 1.975...   \n",
       "126  [2.4275300000000004, 1.2302100000000005, 1.975...   \n",
       "127  [2.4275300000000004, 1.2302100000000005, 1.975...   \n",
       "128  [2.4275300000000004, 1.2302100000000005, 1.975...   \n",
       "129  [2.4275300000000004, 1.2302100000000005, 1.975...   \n",
       "\n",
       "                                           Other Peaks  \n",
       "0    [1.5356500000000004, 2.2646300000000004, 4.68778]  \n",
       "1    [1.5356500000000004, 2.2646300000000004, 4.68778]  \n",
       "2    [1.5356500000000004, 2.2646300000000004, 4.68778]  \n",
       "3    [1.5356500000000004, 2.2646300000000004, 4.68778]  \n",
       "4    [1.5356500000000004, 2.2646300000000004, 4.68778]  \n",
       "..                                                 ...  \n",
       "125  [1.0713800000000004, 1.3849600000000004, 1.535...  \n",
       "126  [1.0713800000000004, 1.3849600000000004, 1.535...  \n",
       "127  [1.0713800000000004, 1.3849600000000004, 1.535...  \n",
       "128  [1.0713800000000004, 1.3849600000000004, 1.535...  \n",
       "129  [1.0713800000000004, 1.3849600000000004, 1.535...  \n",
       "\n",
       "[130 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(peak_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
