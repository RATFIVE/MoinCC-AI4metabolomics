{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input: data, expected peaks (substrate and metabolite)(dictionary?/two lists?\n",
    "data = pd.read_csv('../Data/FA_20231113_2H_yeast_Pyruvate-d3_5.csv')\n",
    "\n",
    "#expected peaks for different substrates\n",
    "Pyruvate_compound = ['Substrate', 'metabolite1', 'metabolite2']\n",
    "peaks_pyruvate= [2.468, 1.2261, 1.9775]\n",
    "\n",
    "spectra_data= data.iloc[:,1:]\n",
    "chem_shifts = data.iloc[:,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# functions so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def peak_fit(intensity, chem_shifts, threshold_percentile):\n",
    "    \"\"\"calculates possible peaks as minima of the second derivative and returns list of peaks\n",
    "\n",
    "    Args:\n",
    "        spectra_data (_type_): x data of spectra\n",
    "        chem_shifts (_type_): y data of spectra\n",
    "        threshold_percentile (int | float): Threshold above which the relevant data lies\n",
    "\n",
    "    Returns:\n",
    "        list: peak positions\n",
    "    \"\"\"\n",
    "    threshold = np.percentile(intensity, threshold_percentile)\n",
    "    first_derivative = np.gradient(intensity, chem_shifts)\n",
    "    second_derivative = np.gradient(first_derivative, chem_shifts)\n",
    "    third_derivative = np.gradient(second_derivative, chem_shifts)\n",
    "    fourth_derivative = np.gradient(third_derivative, chem_shifts)\n",
    "\n",
    "    sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "    peak_mask = (intensity > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "    peak_mask[1:] &= sign_change\n",
    "\n",
    "    return chem_shifts[peak_mask].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakfit_sum(spectra_data, chem_shifts, threshold):\n",
    "    \"\"\"sums up all spectra and returns list of found peaks\n",
    "\n",
    "    Args:\n",
    "        filename (str): file with spectra data\n",
    "        threshold_percentile (int | float): Threshold above which the relevant data lies\n",
    "    \"\"\"\n",
    "    sum_of_spectra = np.sum(spectra_data, axis=1)\n",
    "    # peak_pos = peak_fit(sum_of_spectra, chem_shifts, threshold)\n",
    "\n",
    "    threshold = np.percentile(sum_of_spectra, threshold)\n",
    "\n",
    "    first_derivative = np.gradient(sum_of_spectra, chem_shifts)\n",
    "    second_derivative = np.gradient(first_derivative, chem_shifts)\n",
    "    third_derivative = np.gradient(second_derivative, chem_shifts)\n",
    "    fourth_derivative = np.gradient(third_derivative, chem_shifts)\n",
    "\n",
    "    sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "    peak_mask = (sum_of_spectra > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "    peak_mask[1:] &= sign_change\n",
    "\n",
    "    peak_pos= chem_shifts[peak_mask].tolist()\n",
    "\n",
    "    return peak_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_water_singlet(data: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Diese Funktion wird so angepasst, dass sie jedes Spektrum anhand eines bestimmten Peaks 'normalisiert'.\n",
    "    Jedes Spektrum wird einzeln behandelt.\n",
    "    \"\"\"\n",
    "    # Kopieren des DataFrames, um die ursprünglichen Daten nicht zu verändern\n",
    "    data_normalized = pd.DataFrame()\n",
    "    data_normalized['chem_shift'] = data.iloc[:,0]  # Chemische Verschiebungen beibehalten\n",
    "    \n",
    "    # Über jede Spektrumsspalte iterieren (jedes Spektrum)\n",
    "    for col in data.columns[1:]:\n",
    "        intensity = data[col]\n",
    "        chem_shifts = data.iloc[:, 0]\n",
    "        \n",
    "        # Nutzung der peak_fit Funktion, um Peaks für jedes Spektrum zu ermitteln\n",
    "        peak_pos = peak_fit(intensity.values, chem_shifts.values, 85)  # Annahme: threshold_percentile=85\n",
    "        \n",
    "        # Bestimmung des dem Wasserpeak am nächsten liegenden Peaks\n",
    "        water = 4.7\n",
    "        \n",
    "        if peak_pos:\n",
    "            closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "            \n",
    "            # Adjustierung der chemischen Verschiebung basierend auf dem nächsten Peak\n",
    "            adjusted_shifts = chem_shifts + (water - closest_peak)\n",
    "            data_normalized[col] = intensity.set_axis(adjusted_shifts.index)\n",
    "        else:\n",
    "            # Falls keine Peaks gefunden wurden, Kopie der Originalintensitäten\n",
    "            data_normalized[col] = intensity\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_water_singlet(data: pd.DataFrame, threshold=85, delta_threshold=2, min_threshold=50):\n",
    "    \"\"\"\n",
    "    Normalisiert jedes Spektrum im DataFrame basierend auf dem nächsten Wasserpeak, wobei der Threshold angepasst wird.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Spectra-Daten.\n",
    "        threshold (int, optional): Anfangsschwelle für die Peak-Suche. Standardmäßig 85.\n",
    "        delta_threshold (int, optional): Reduktionsbetrag für den Threshold. Standardmäßig 2.\n",
    "        min_threshold (int, optional): Minimale Schwelle für die Peak-Suche. Standardmäßig 50.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit normalisierten Daten.\n",
    "    \"\"\"\n",
    "    data_normalized = pd.DataFrame()\n",
    "    data_normalized['chem_shift'] = data.iloc[:,0]  \n",
    "    \n",
    "    # Iteration durch jede Spalte (jedes Spektrum).\n",
    "    for col in data.columns[1:]:\n",
    "        intensity = data[col]\n",
    "        chem_shifts = data.iloc[:, 0]\n",
    "        \n",
    "        current_threshold = threshold\n",
    "        peak_found = False\n",
    "        while not peak_found and current_threshold >= min_threshold:\n",
    "            # Nutzung der peak_fit Funktion mit dem aktuellen Threshold\n",
    "            peak_pos = peak_fit(intensity.values, chem_shifts.values, current_threshold)\n",
    "            \n",
    "            # Suche nach Peaks im Wasserbereich\n",
    "            water_peaks = [peak for peak in peak_pos if 4.6 <= peak <= 4.8]\n",
    "            \n",
    "            if water_peaks:\n",
    "                closest_peak = min(water_peaks, key=lambda x: abs(x - 4.7))\n",
    "                peak_found = True\n",
    "            else:\n",
    "                current_threshold -= delta_threshold\n",
    "        \n",
    "        # Wenn ein passender Peak gefunden wurde, chemische Schichten adjustieren\n",
    "        if peak_found:\n",
    "            adjusted_shifts = chem_shifts + (4.7 - closest_peak)\n",
    "            data_normalized[col] = intensity.set_axis(adjusted_shifts.index)\n",
    "        else:\n",
    "            # Sicherheitsfallback, falls kein Peak gefunden wurde\n",
    "            print(f\"Kein Peak für {col} im Bereich von 4.6 bis 4.8 gefunden, auch nicht mit min_threshold={min_threshold}.\")\n",
    "            data_normalized[col] = intensity  # Originalintensitäten übernehmen\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_water(data:pd.DataFrame):\n",
    "    \"\"\"adjusts the data to the chem_shift(water) = 4.7, based on the closest peak in summed up spectra\n",
    "    --> needs existing function 'peakfit_sum', peak_fit\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): spectra data with chem_shift in first column\n",
    "\n",
    "    Returns:\n",
    "        data_normalized (pd.DataFrame): dataframe with normalized data\n",
    "    \"\"\"\n",
    "\n",
    "    spectra_data= data.iloc[:,1:]\n",
    "    chem_shifts = data.iloc[:,0] \n",
    "\n",
    "    peak_pos = peakfit_sum(spectra_data, chem_shifts, 85)\n",
    "\n",
    "    #identify water peak (closest to 4.7\n",
    "    water = 4.7\n",
    "    closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "\n",
    "    # reposition the whole spectra\n",
    "    data_normalized = pd.DataFrame(chem_shifts.copy() + ( 4.7 - closest_peak))\n",
    "    data_normalized = pd.concat([data_normalized, data.iloc[:, 1:]], axis=1)\n",
    "\n",
    "    # Neubenennung der Spalten, um die Originalstruktur zu erhalten\n",
    "    data_normalized.columns = data.columns\n",
    "\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_identify(data_normalized: pd.DataFrame, expected_peaks: list,  compound_names: list, initial_threshold = 85, max_shift = 0.15):\n",
    "    \"\"\"searches for peaks and matches them to the closest expected peak respecting the maximal shift. \n",
    "    Unidentified peaks are added to other(list). \n",
    "    Threshold is lowered until all expected peaks are found or number of other peaks succeeds numer of expected peaks\n",
    "    \n",
    "    needs existing function 'peakfit_sum'\n",
    "    \n",
    "    Args:\n",
    "        data_normalized (pd.DataFrame): _description_\n",
    "        compound_names (list): list with names of expected compunds (optional)\n",
    "        expected_peaks (list): list with positions of expected peaks\n",
    "        max_shift: maximum distance to expected peak position for \n",
    "\n",
    "    Returns:\n",
    "        found (list): list with identified peaks most likely the expected ones\n",
    "        other (list):  list with other found peaks\n",
    "    \"\"\"\n",
    "\n",
    "    spectra_data= data_normalized.iloc[:,1:]\n",
    "    chem_shifts = data_normalized.iloc[:,0]\n",
    "\n",
    "    #create enpty lists for found and identified peaks\n",
    "    found = [None] * len(expected_peaks)\n",
    "    other = []\n",
    "    threshold = initial_threshold\n",
    "\n",
    "    while None in found or len(other) <= len(found):\n",
    "        \n",
    "        #search for peaks above given threshold\n",
    "        detected_peaks = peakfit_sum(spectra_data, chem_shifts, threshold)\n",
    "        \n",
    "        for peak in detected_peaks:\n",
    "            distances = [abs(peak - expected_peak) for expected_peak in expected_peaks]\n",
    "            min_distance = min(distances)\n",
    "            index = distances.index(min_distance)\n",
    "            \n",
    "            if min_distance <= max_shift:\n",
    "                if found[index] is None:\n",
    "                    found[index] = peak\n",
    "                elif found[index] != peak:\n",
    "                    other.append(peak)\n",
    "            elif min_distance > max_shift:\n",
    "                other.append(peak)\n",
    "            \n",
    "        threshold -= 2\n",
    "\n",
    "        if threshold < 0 or None not in found or len(other) > len(found):\n",
    "            if None not in found:\n",
    "                #print('alle peaks gefunden')\n",
    "                break\n",
    "            else: \n",
    "                break\n",
    "\n",
    "    print(\"Found Peaks: \", found)\n",
    "    print(\"Other Peaks: \", other)\n",
    "\n",
    "    return found, other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_df(data, expected_peaks, compound_names, shift_tol=0.01, viz=True, min_cols_per_section = 20):\n",
    "\n",
    "    # normalize data\n",
    "    df = normalize_water(data)\n",
    "   \n",
    "    # Split into section with at least 20 columns each\n",
    "    cols_to_divide = len(df.columns)-1 #-1 because first column is chemical shift\n",
    "    num_sections = max(cols_to_divide // min_cols_per_section, 1) if cols_to_divide > min_cols_per_section else 1\n",
    "\n",
    "    cols_per_section = cols_to_divide // num_sections\n",
    "    extra_cols = cols_to_divide % num_sections  # Extra columns to distribute\n",
    "\n",
    "    sections = []\n",
    "    start_col = 1 #ignore first column\n",
    "    col_sect = []\n",
    "\n",
    "    for section in range(num_sections):\n",
    "        extra = 1 if section < extra_cols else 0\n",
    "        end_col = start_col + cols_per_section + extra\n",
    "        #sections.append(df.iloc[:, start_col:end_col])\n",
    "        sections.append(df.iloc[:, [0] + list(range(start_col, end_col))]) #add column with chem_shift to each section\n",
    "        start_col = end_col\n",
    "        col_sect.extend([f\"{section + 1}\"] * (cols_per_section + extra)) #column entries for final dataframe\n",
    "\n",
    "    found_lists = []\n",
    "    other_lists = []\n",
    "\n",
    "    # Find peaks for each section\n",
    "    for df_section in sections:\n",
    "        found, other = peak_identify(df_section, expected_peaks, compound_names)\n",
    "        found_lists.append(found)\n",
    "        other_lists.append(other)\n",
    "\n",
    "    \n",
    "    #create final dataframe\n",
    "    final_df = pd.DataFrame({\n",
    "        'Column': df.columns[1:],  # Exclude the chemical shift from the final DataFrame columns\n",
    "        'section': col_sect\n",
    "    })\n",
    "\n",
    "    \n",
    "    peaks_data = {'Found Peaks': [], 'Other Peaks': []}\n",
    "    for i in range(num_sections):\n",
    "        section_length = len(sections[i].columns) - 1  # -1 to ignore the chemical shift column\n",
    "        peaks_data['Found Peaks'].extend([found_lists[i]] * section_length)\n",
    "        peaks_data['Other Peaks'].extend([other_lists[i]] * section_length)\n",
    "\n",
    "    final_df['Found Peaks'] = peaks_data['Found Peaks']\n",
    "    final_df['Other Peaks'] = peaks_data['Other Peaks']\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9673300000000005]\n",
      "Other Peaks:  [1.5356500000000004, 2.2646300000000004, 4.68778]\n",
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9673300000000005]\n",
      "Other Peaks:  [1.3849600000000004, 1.5356500000000004, 4.68778]\n",
      "Found Peaks:  [2.4275300000000004, 1.2261300000000004, 1.9714100000000003]\n",
      "Other Peaks:  [1.3890400000000005, 1.5356500000000004, 4.6918500000000005]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9714100000000003]\n",
      "Other Peaks:  [1.0673100000000004, 1.3849600000000004, 1.5356500000000004, 4.70814]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9714100000000003]\n",
      "Other Peaks:  [1.0713800000000004, 1.3808900000000004, 1.5356500000000004, 4.70814]\n",
      "Found Peaks:  [2.4275300000000004, 1.2302100000000005, 1.9754800000000003]\n",
      "Other Peaks:  [1.0713800000000004, 1.3849600000000004, 1.5356500000000004, 4.716290000000001]\n"
     ]
    }
   ],
   "source": [
    "peak_df = peak_df(data, expected_peaks=peaks_pyruvate, compound_names= Pyruvate_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0713800000000004, 1.3849600000000004, 1.5356500000000004, 4.716290000000001]\n"
     ]
    }
   ],
   "source": [
    "print(peak_df['Other Peaks'].loc[127])#[127])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectraAnalysis:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def peakfit_sum(self, spectra_data, chem_shifts, threshold):\n",
    "        \"\"\"Summen der Spektren und Rückgabe einer Liste gefundener Peaks\"\"\"\n",
    "        sum_of_spectra = np.sum(spectra_data, axis=1)\n",
    "        threshold = np.percentile(sum_of_spectra, threshold)\n",
    "\n",
    "        first_derivative = np.gradient(sum_of_spectra, chem_shifts)\n",
    "        second_derivative = np.gradient(first_derivative, chem_shifts)\n",
    "        third_derivative = np.gradient(second_derivative, chem_shifts)\n",
    "        fourth_derivative = np.gradient(third_derivative, chem_shifts)\n",
    "\n",
    "        sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "        peak_mask = (sum_of_spectra > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "        peak_mask[1:] &= sign_change\n",
    "\n",
    "        peak_pos = chem_shifts[peak_mask].tolist()\n",
    "        return peak_pos\n",
    "\n",
    "    def normalize_water(self, data):\n",
    "        \"\"\"Anpassung der Daten basierend auf dem Wasser-Peak\"\"\"\n",
    "        spectra_data = data.iloc[:, 1:]\n",
    "        chem_shifts = data.iloc[:, 0]\n",
    "\n",
    "        peak_pos = self.peakfit_sum(spectra_data, chem_shifts, 85)\n",
    "        water = 4.7\n",
    "        closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "\n",
    "        data_normalized = pd.DataFrame(chem_shifts.copy() + (4.7 - closest_peak))\n",
    "        data_normalized = pd.concat([data_normalized, data.iloc[:, 1:]], axis=1)\n",
    "        data_normalized.columns = data.columns\n",
    "        return data_normalized\n",
    "\n",
    "    def peak_identify(self, data_normalized, expected_peaks, compound_names, initial_threshold=85, max_shift=0.15):\n",
    "        \"\"\"Identifizierung von Peaks und Zuordnung zu erwarteten Peaks\"\"\"\n",
    "        spectra_data = data_normalized.iloc[:, 1:]\n",
    "        chem_shifts = data_normalized.iloc[:, 0]\n",
    "\n",
    "        found = [None] * len(expected_peaks)\n",
    "        other = []\n",
    "        threshold = initial_threshold\n",
    "\n",
    "        while None in found or len(other) <= len(found):\n",
    "            detected_peaks = self.peakfit_sum(spectra_data, chem_shifts, threshold)\n",
    "            for peak in detected_peaks:\n",
    "                distances = [abs(peak - expected_peak) for expected_peak in expected_peaks]\n",
    "                min_distance = min(distances)\n",
    "                index = distances.index(min_distance)\n",
    "\n",
    "                if min_distance <= max_shift:\n",
    "                    if found[index] is None:\n",
    "                        found[index] = peak\n",
    "                    elif found[index] != peak:\n",
    "                        other.append(peak)\n",
    "                else:\n",
    "                    other.append(peak)\n",
    "\n",
    "            threshold -= 2\n",
    "            if threshold < 0 or None not in found or len(other) > len(found):\n",
    "                break\n",
    "\n",
    "        print(\"Found Peaks: \", found)\n",
    "        print(\"Other Peaks: \", other)\n",
    "\n",
    "        return found, other\n",
    "\n",
    "    def peak_df(self, data, expected_peaks, compound_names, min_cols_per_section=20):\n",
    "        \"\"\"creates dataframe with expected peaks and other found peaks\"\"\"\n",
    "        #normalize data\n",
    "        df = self.normalize_water(data)\n",
    "    \n",
    "        # Split into section with at least 20 columns each\n",
    "        cols_to_divide = len(df.columns)-1 #-1 because first column is chemical shift\n",
    "        num_sections = max(cols_to_divide // min_cols_per_section, 1) if cols_to_divide > min_cols_per_section else 1\n",
    "\n",
    "        cols_per_section = cols_to_divide // num_sections\n",
    "        extra_cols = cols_to_divide % num_sections  # Extra columns to distribute\n",
    "\n",
    "        sections = []\n",
    "        start_col = 1 #ignore first column\n",
    "        col_sect = []\n",
    "\n",
    "        for section in range(num_sections):\n",
    "            extra = 1 if section < extra_cols else 0\n",
    "            end_col = start_col + cols_per_section + extra\n",
    "            #sections.append(df.iloc[:, start_col:end_col])\n",
    "            sections.append(df.iloc[:, [0] + list(range(start_col, end_col))]) #add column with chem_shift to each section\n",
    "            start_col = end_col\n",
    "            col_sect.extend([f\"{section + 1}\"] * (cols_per_section + extra)) #column entries for final dataframe\n",
    "\n",
    "        found_lists = []\n",
    "        other_lists = []\n",
    "\n",
    "        # Find peaks for each section\n",
    "        for df_section in sections:\n",
    "            found, other = self.peak_identify(df_section, expected_peaks, compound_names)\n",
    "            found_lists.append(found)\n",
    "            other_lists.append(other)\n",
    "\n",
    "        \n",
    "        #create final dataframe\n",
    "        final_df = pd.DataFrame({\n",
    "            'Column': df.columns[1:],  # Exclude the chemical shift from the final DataFrame columns\n",
    "            'section': col_sect\n",
    "        })\n",
    "\n",
    "        \n",
    "        peaks_data = {'Found Peaks': [], 'Other Peaks': []}\n",
    "        for i in range(num_sections):\n",
    "            section_length = len(sections[i].columns) - 1  # -1 to ignore the chemical shift column\n",
    "            peaks_data['Found Peaks'].extend([found_lists[i]] * section_length)\n",
    "            peaks_data['Other Peaks'].extend([other_lists[i]] * section_length)\n",
    "\n",
    "        final_df['Found Peaks'] = peaks_data['Found Peaks']\n",
    "        final_df['Other Peaks'] = peaks_data['Other Peaks']\n",
    "\n",
    "        return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak_positions = analyser.peakfit_sum(spectra_data, chem_shifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peak_df(data, expected_peaks=peaks_pyruvate, compound_names= Pyruvate_compound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "import sys\n",
    "sys.path.append('../app')\n",
    "\n",
    "from peakpos_df import SpectraAnalysis\n",
    "# Jetzt können Sie SpectraAnalysis nutzen\n",
    "analyser = SpectraAnalysis(data= data, expected_peaks=peaks_pyruvate,)\n",
    "peak_positions = analyser.peak_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adjusted class\n",
    "added time dependency of maximum shift: no shift > 0.02 for each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SpectraAnalysis:\n",
    "    def __init__(self, data, expected_peaks):\n",
    "        self.data = data\n",
    "        self.expected_peaks = expected_peaks\n",
    "        self.spectra_data = data.iloc[:, 1:]\n",
    "        self.chem_shifts = data.iloc[:, 0]\n",
    "\n",
    "    def peakfit_sum(self, threshold):\n",
    "        \"\"\"sums up all spectra and returns list of found peaks above threshold percentile\n",
    "\n",
    "        Args:\n",
    "            spectra_data(DataFrame): extracted intensitys from DataFrame data\n",
    "            chem_shifts(list): extracted from DataFrame data\n",
    "        \n",
    "        Returns:\n",
    "            peak_pos(list): list with found peak positions\n",
    "        \"\"\"\n",
    "        sum_of_spectra = np.sum(self.spectra_data, axis=1)\n",
    "        threshold = np.percentile(sum_of_spectra, threshold)\n",
    "\n",
    "        first_derivative = np.gradient(sum_of_spectra, self.chem_shifts)\n",
    "        second_derivative = np.gradient(first_derivative, self.chem_shifts)\n",
    "        third_derivative = np.gradient(second_derivative, self.chem_shifts)\n",
    "        fourth_derivative = np.gradient(third_derivative, self.chem_shifts)\n",
    "\n",
    "        sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "        peak_mask = (sum_of_spectra > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "        peak_mask[1:] &= sign_change\n",
    "\n",
    "        peak_pos = self.chem_shifts[peak_mask].tolist()\n",
    "        return peak_pos\n",
    "\n",
    "    def normalize_water(self):\n",
    "        \"\"\"shifts chem_shift values based on summed up spectra, so water peak is normalized to 4.7\n",
    "\n",
    "        Args:\n",
    "            spectra_data(DataFrame): extracted intensitys from DataFrame data\n",
    "            chem_shifts(list): extracted from DataFrame data\n",
    "        \n",
    "        Returns:\n",
    "            data_normalized(DataFrame): DataFrame with normalized Data   \n",
    "            norm_shift(Float): value by which chem_shift was shifted\n",
    "\n",
    "        \"\"\"    \n",
    "        peak_pos = self.peakfit_sum(threshold = 85)\n",
    "        water = 4.7\n",
    "        closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "        \n",
    "        norm_shift = (4.7 - closest_peak)\n",
    "\n",
    "        data_normalized = pd.DataFrame(self.chem_shifts.copy() + norm_shift)\n",
    "        data_normalized = pd.concat([data_normalized, self.data.iloc[:, 1:]], axis=1)\n",
    "        data_normalized.columns = self.data.columns\n",
    "        return data_normalized, norm_shift\n",
    "\n",
    "    def peak_identify(self, data_normalized, initial_threshold=85, max_shift=0.5): #max_shift maybe\n",
    "        \"\"\"Searches for peaks and adds them to list based on expected values. \n",
    "        Threshold is continually lowered until all expected peaks are found or more unknown peaks are found than expected\n",
    "        \n",
    "        Args:\n",
    "\n",
    "            self.expected_peaks(list): chem shift values of expected peaks\n",
    "            data_normalized(DataFrame): data normalized, result of function normalize_water\n",
    "            initial_threshold(int, optional): starting percentile above which peaks are recognizedDefaults to 85\n",
    "            max_shift: maximum value that chem_shift can be shifted from expected peakposition for identification\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            found(list): list of actual peak positions in order of expected peaks\n",
    "            other(list): list of unidentified found peaks\n",
    "        \"\"\"\n",
    "        spectra_data = data_normalized.iloc[:, 1:]\n",
    "        chem_shifts = data_normalized.iloc[:, 0]\n",
    "\n",
    "        found = [None] * len(self.expected_peaks)\n",
    "        other = []\n",
    "        threshold = initial_threshold\n",
    "\n",
    "        while None in found or len(other) <= len(found):\n",
    "            detected_peaks = self.peakfit_sum(threshold)\n",
    "            for peak in detected_peaks:\n",
    "                distances = [abs(peak - expected_peak) for expected_peak in self.expected_peaks]\n",
    "                min_distance = min(distances)\n",
    "                index = distances.index(min_distance)\n",
    "\n",
    "                if min_distance <= max_shift:\n",
    "                    if found[index] is None:\n",
    "                        found[index] = peak\n",
    "                    elif found[index] != peak:\n",
    "                        other.append(peak)\n",
    "                else:\n",
    "                    other.append(peak)\n",
    "\n",
    "            threshold -= 2\n",
    "            if threshold < 0 or None not in found or len(other) > len(found):\n",
    "                break\n",
    "\n",
    "        #print(\"Found Peaks: \", found)\n",
    "        #print(\"Other Peaks: \", other)\n",
    "\n",
    "        return found, other\n",
    "    \n",
    "\n",
    "    def peak_df(self, min_cols_per_section=20):\n",
    "        \"\"\"Normalizes the given data to chem_shift(water) = 4.7 \n",
    "        splits spectra into sections over time\n",
    "        identifies peaks in summed up sections\n",
    "\n",
    "        Args:\n",
    "            data (dataFrame): spectrum data; 1.column with chemical shift, athers with intensity\n",
    "            expected_peaks (list): list of chem_shifts of expected peaks\n",
    "            min_cols_per_section (int, optional): minimum number if spectra that are summed up to find peaks. Defaults to 20.\n",
    "\n",
    "        Returns:\n",
    "            final_df(DataFrame): Dtaframe with found peak positions\n",
    "            final_df['Found Peaks'] : list of actual peak positions in order of expected peaks\n",
    "            peaks_data['Other Peaks']: list of unidentified found peaks\n",
    "        \"\"\"\n",
    "        #normalize data\n",
    "        df, norm_shift = self.normalize_water()\n",
    "    \n",
    "        # Split into section with at least 20 columns each\n",
    "        cols_to_divide = len(df.columns)-1 #-1 because first column is chemical shift\n",
    "        num_sections = max(cols_to_divide // min_cols_per_section, 1) if cols_to_divide > min_cols_per_section else 1\n",
    "\n",
    "        cols_per_section = cols_to_divide // num_sections\n",
    "        extra_cols = cols_to_divide % num_sections  # Extra columns to distribute\n",
    "\n",
    "        sections = []\n",
    "        start_col = 1 #ignore first column\n",
    "        col_sect = []\n",
    "\n",
    "        for section in range(num_sections):\n",
    "            extra = 1 if section < extra_cols else 0\n",
    "            end_col = start_col + cols_per_section + extra\n",
    "            #sections.append(df.iloc[:, start_col:end_col])\n",
    "            sections.append(df.iloc[:, [0] + list(range(start_col, end_col))]) #add column with chem_shift to each section\n",
    "            start_col = end_col\n",
    "            col_sect.extend([f\"{section + 1}\"] * (cols_per_section + extra)) #column entries for final dataframe\n",
    "\n",
    "        found_lists = []\n",
    "        other_lists = []\n",
    "\n",
    "        # Find peaks for each section\n",
    "        \n",
    "        for df_section in sections:\n",
    "\n",
    "            found, other = self.peak_identify(data_normalized = df_section)\n",
    "            found_lists.append(found)\n",
    "            other_lists.append(other)\n",
    "\n",
    "\n",
    "        #'unnormalize' the values\n",
    "        for i in range(len(found_lists)):\n",
    "            found_lists[i] = [x - norm_shift for x in found_lists[i]]\n",
    "            other_lists[i] = [x - norm_shift for x in other_lists[i]]\n",
    "\n",
    "        #create final dataframe\n",
    "        final_df = pd.DataFrame({\n",
    "            'Column': df.columns[1:],  # Exclude the chemical shift from the final DataFrame columns\n",
    "            'section': col_sect\n",
    "        })\n",
    "\n",
    "        peaks_data = {'Found Peaks': [], 'Other Peaks': []}\n",
    "\n",
    "        for i in range(num_sections):\n",
    "            section_length = len(sections[i].columns) - 1  # -1 to ignore the chemical shift column\n",
    "            peaks_data['Found Peaks'].extend([found_lists[i]] * section_length)\n",
    "            peaks_data['Other Peaks'].extend([other_lists[i]] * section_length)\n",
    "\n",
    "\n",
    "        final_df['Found Peaks'] = peaks_data['Found Peaks']\n",
    "        final_df['Other Peaks'] = peaks_data['Other Peaks']\n",
    "\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Um Ihren Anforderungen zu entsprechen, werde ich den relevanten Teil der `peak_identify` Methode und die Art und Weise, wie sie in der `peak_df` Methode aufgerufen \n",
    "# wird, so anpassen, dass in den weiteren Sektionen nicht mehr die ursprünglichen `expected_peaks` für die Distanzbestimmung verwendet werden, \n",
    "# sondern stattdessen die gefundenen Peaks der vorherigen Sektion. Hier ist der angepasste Code:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class SpectraAnalysis:\n",
    "    def __init__(self, data, expected_peaks):\n",
    "        self.data = data\n",
    "        self.expected_peaks = expected_peaks\n",
    "        self.spectra_data = data.iloc[:, 1:]\n",
    "        self.chem_shifts = data.iloc[:, 0]\n",
    "\n",
    "    def peakfit_sum(self, threshold):\n",
    "        sum_of_spectra = np.sum(self.spectra_data, axis=1)\n",
    "        threshold = np.percentile(sum_of_spectra, threshold)\n",
    "        first_derivative = np.gradient(sum_of_spectra, self.chem_shifts)\n",
    "        second_derivative = np.gradient(first_derivative, self.chem_shifts)\n",
    "        third_derivative = np.gradient(second_derivative, self.chem_shifts)\n",
    "        fourth_derivative = np.gradient(third_derivative, self.chem_shifts)\n",
    "        sign_change = np.diff(np.sign(third_derivative)) != 0\n",
    "        peak_mask = (sum_of_spectra > threshold) & (second_derivative < 0) & (fourth_derivative > 0)\n",
    "        peak_mask[1:] &= sign_change\n",
    "        peak_pos = self.chem_shifts[peak_mask].tolist()\n",
    "        return peak_pos\n",
    "\n",
    "    def normalize_water(self):\n",
    "        peak_pos = self.peakfit_sum(threshold = 85)\n",
    "        water = 4.7\n",
    "        closest_peak = min(peak_pos, key=lambda x: abs(x - water))\n",
    "        \n",
    "        norm_shift = (4.7 - closest_peak)\n",
    "        data_normalized = pd.DataFrame(self.chem_shifts.copy() + norm_shift)\n",
    "        data_normalized = pd.concat([data_normalized, self.data.iloc[:, 1:]], axis=1)\n",
    "        data_normalized.columns = self.data.columns\n",
    "        return data_normalized, norm_shift\n",
    "\n",
    "    def peak_identify(self, data_normalized, reference_peaks, initial_threshold=85, max_shift=0.5):\n",
    "        spectra_data = data_normalized.iloc[:, 1:]\n",
    "        chem_shifts = data_normalized.iloc[:, 0]\n",
    "\n",
    "        found = [None] * len(reference_peaks)\n",
    "        other = []\n",
    "        threshold = initial_threshold\n",
    "\n",
    "        while None in found or len(other) <= len(found):\n",
    "            detected_peaks = self.peakfit_sum(threshold)\n",
    "            for peak in detected_peaks:\n",
    "                distances = [abs(peak - expected_peak) for expected_peak in reference_peaks]\n",
    "                min_distance = min(distances)\n",
    "                index = distances.index(min_distance)\n",
    "\n",
    "                if min_distance <= max_shift:\n",
    "                    if found[index] is None:\n",
    "                        found[index] = peak\n",
    "                    elif abs(peak - found[index]) > max_shift:\n",
    "                        other.append(peak)\n",
    "                else:\n",
    "                    other.append(peak)\n",
    "\n",
    "            threshold -= 2\n",
    "            if threshold < 0 or None not in found or len(other) > len(found):\n",
    "                break\n",
    "        # replace remaining unfound peak positions with expected chem_shift value \n",
    "        for i, peak in enumerate(found):\n",
    "            if peak is None:\n",
    "                found[i] = reference_peaks[i]  \n",
    "\n",
    "\n",
    "        return found, other\n",
    "    \n",
    "\n",
    "    def peak_df(self, min_cols_per_section=20):\n",
    "        df, norm_shift = self.normalize_water()\n",
    "    \n",
    "        cols_to_divide = len(df.columns)-1 \n",
    "        num_sections = max(cols_to_divide // min_cols_per_section, 1) if cols_to_divide > min_cols_per_section else 1\n",
    "\n",
    "        cols_per_section = cols_to_divide // num_sections\n",
    "        extra_cols = cols_to_divide % num_sections  \n",
    "\n",
    "        sections = []\n",
    "        start_col = 1\n",
    "        col_sect = []\n",
    "\n",
    "        for section in range(num_sections):\n",
    "            extra = 1 if section < extra_cols else 0\n",
    "            end_col = start_col + cols_per_section + extra\n",
    "            sections.append(df.iloc[:, [0] + list(range(start_col, end_col))]) \n",
    "            start_col = end_col\n",
    "            col_sect.extend([f\"{section + 1}\"] * (cols_per_section + extra)) \n",
    "\n",
    "        reference_peaks = self.expected_peaks # Neu\n",
    "        found_lists = []\n",
    "        other_lists = []\n",
    "\n",
    "        # Find peaks for each section \n",
    "        for df_section in sections:\n",
    "            found, other = self.peak_identify(data_normalized = df_section, reference_peaks = reference_peaks) # Geändert\n",
    "            found_lists.append(found)\n",
    "            other_lists.append(other)\n",
    "            reference_peaks = found # Neu: Update reference peaks\n",
    "\n",
    "        for i in range(len(found_lists)):\n",
    "            found_lists[i] = [x - norm_shift if x is not None else None for x in found_lists[i]] # Angepasst für None-Werte\n",
    "            other_lists[i] = [x - norm_shift for x in other_lists[i]]\n",
    "\n",
    "        final_df = pd.DataFrame({\n",
    "            'Column': df.columns[1:],  \n",
    "            'section': col_sect\n",
    "        })\n",
    "\n",
    "        peaks_data = {'Found Peaks': [], 'Other Peaks': []}\n",
    "\n",
    "        for i in range(num_sections):\n",
    "            section_length = len(sections[i].columns) - 1 \n",
    "            peaks_data['Found Peaks'].extend([found_lists[i]] * section_length)\n",
    "            peaks_data['Other Peaks'].extend([other_lists[i]] * section_length)\n",
    "\n",
    "        final_df['Found Peaks'] = peaks_data['Found Peaks']\n",
    "        final_df['Other Peaks'] = peaks_data['Other Peaks']\n",
    "\n",
    "        return final_df\n",
    "\n",
    "# Geänderte Stellen:\n",
    "# - In `peak_identify`, habe ich den Parameter `reference_peaks` hinzugefügt, um entweder die `expected_peaks` oder die gefundenen Peaks der vorherigen Sektion zu übergeben.\n",
    "# - Die Zeile, die `reference_peaks` vor jedem Aufruf von `peak_identify` in `peak_df` aktualisiert, macht genau die Anpassung, die Sie beschrieben haben: \n",
    "# In jeder weiteren Sektion wird die Abweichung nicht mehr im Vergleich zu den `expected_peaks`, sondern zu den in der vorherigen Sektion gefundenen Peaks berechnet.\n",
    "# - Kleine Anpassung in der Behandlung von `None`-Werten bei der 'Unnormalisierung' der gefundenen Peaks, um Fehler zu vermeiden.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
